[`Lenguajes de Programaci贸n`](../../README.md) > [`Unidad 1`](../README.md) > Generaci贸n de c贸digo ejecutable

# Generaci贸n de c贸digo ejecutable

Una vez que tenemos el dise帽o de un lenguaje de programaci贸n mediante su especificaci贸n formal, procedemos a darle vida, para ello necesitamos *generar c贸digo ejecutable*.

Para ejemplificar todos los conceptos asociados a la generaci贸n de c贸digo ejecutable, integraremos la especificaci贸n de la sintaxis y sem谩ntica de **MiniLisp**. Las fases en general que seguiremos para dise帽ar nuestros lenguajes de programaci贸n son:

1. Especificaci贸n de la sintaxis.
1. Especificaci贸n de la sem谩ntica.
1. Elecci贸n del lenguaje anfitri贸n.
1. Implementaci贸n del an谩lisis l茅xico.
1. Implementaci贸n del an谩lisis sint谩ctico.
1. Implementaci贸n del an谩lisis sem谩ntico.
1. Integraci贸n.

## Especificaci贸n de la sintaxis

Como vimos en el Tema 4, la especificaci贸n de la sintaxis se da en dos partes: *Sintaxis concreta* y *sintaxis abstracta*. A continuaci贸n la especificaci贸n de ambos tipos de sintaxis para **MiniLisp**:

![img](imgs/img01.png)

## Especificaci贸n de la sem谩ntica

Como vimos en los Temas 5 y 6, la especificaci贸n de la sintaxis puede darse usando un enfoque operacional de dos maneras: natural o estructural. Para los fines de una implementaci贸n siempre es m谩s conveniente trabajar con una sem谩ntica natural, mientras que para realizar pruebas sobre el lenguaje, es m谩s conveniente usar una sem谩ntica estructural. A continuaci贸n la sem谩ntica natural de **MiniLisp**:

![img](imgs/img02.png)

## Elecci贸n del lenguaje anfitri贸n

Ahora que tenemos el dise帽o de nuestro lenguaje por medio de la especificaci贸n de la sintaxis y la sem谩ntica, procedemos a realizar la implementaci贸n. Dentro de esta implementaci贸n tenemos dos lenguajes de programaci贸n involucrados:

- **Lenguaje objetivo:** Es el lenguaje para el cual daremos la implementaci贸n, el que estamos dise帽ando, en este caso el lenguaje **MiniLisp**.

- **Lenguaje anfitri贸n:** El que usaremos para lograr la implementaci贸n, el que har谩 todo el trabajo tras bambalinas. Por ejemplo el lenguaje anfitri贸n de **Java** es **C**. En nuestro caso usaremos **Haskell** como lenguaje anfitri贸n.

## An谩lisis l茅xico

En esta etapa tenemos b谩sicamente las siguientes fases:

- Se analiza la entrada caracter a caracter y se divide en una serie de unidades elementales: los componentes l茅xicos llamados *lexemas* o *tokens*.

- Cada token se clasifica en una categor铆a y puede recibir uno o m谩s atributos con informaci relevante para otras fases.

Definiremos el analizador l茅xico por medio de una funci贸n `lexer`:

```haskell
lexer :: String -> [Token]
```

Nuestra funci贸n `lexer` requiere antes que nada la definici贸n del tipo `Token` que representa los tokens a capturar dentro del lenguaje.

```haskell
data Token = TokenNum Int
           | TokenSuma
           | TokenResta
           | TokenMult
           | TokenDiv
           | TokenPA
           | TokenPC
           deriving(Show)
```

Definimos entonces la funci贸n `lexer`. Esta funci贸n lee caracter a caracter y clasifica cada una de las cosas que encuentra en una categor铆a dependiendo del tipo de token correspondiente.

```haskell
lexer :: String -> [Token]
lexer [] = []
lexer (' ' : xs) = lexer xs
lexer ('(' : xs) = TokenPA:(lexer xs)
lexer (')' : xs) = TokenPC:(lexer xs)
lexer ('+' : xs) = TokenSuma:(lexer xs)
lexer ('-' : xs) = TokenResta:(lexer xs)
lexer ('*' : xs) = TokenMult:(lexer xs)
lexer ('/' : xs) = TokenDiv:(lexer xs)
lexer (x:xs)
    | isDigit x = lexNum (x:xs)

lexNum :: String -> [Token]
lexNum cs = TokenNum (read num) : lexer rest
      where (num,rest) = span isDigit cs
```

```bash
> lexer "1729"
> [TokenNum 1729]
> lexer "(+ 18 35)"
> [TokenPA, TokenSuma, TokenNum 18, TokenNum 35, TokenPC]
> lexer "(+ (- 4 0) (* 5 5))"
> [TokenPA, TokenSuma, TokenPA, TokenResta, TokenNum 4, TokenNum 0, TokenPC, TokenPA, TokenMult, TokenNum 5, TokenNum 5, TokenPC, TokenPC]
```

## An谩lisis sint谩ctico

Partiendo de los componentes l茅xicos, en esta fase se conforman las estructuras presentes en el c贸digo de acuerdo con una gram谩tica de la sintaxis concreta. Se construye el ASA correspondiente.

En an谩lisis sint谩ctico en general puede complicarse de lenguaje a lenguaje, por lo que hoy en d铆a existen diversas herramientas que nos pueden ayudar a realizar este proceso sin mucho esfuerzo. Tu curso de **Compiladores** profundizar谩 mucho en c贸mo es que trabajan estas herramientas.

Sin embargo, debe quedar claro que el proceso en general, consiste en recorrer los componentes l茅xicos y construir la estructura de 谩rbol correspondiente.

Para representar los ASA en **Haskell** haremos uso del siguiente tipo de dato, mismo que se basa en la especificaci贸n de la sem谩ntica abstracta.

```haskell
data ASA = Num Int
          | Suma ASA ASA
          | Resta ASA ASA
          | Mult ASA ASA
          | Div ASA ASA
          deriving(Show)
```

En este curso haremos uso de la herramienta [**Happy** ](https://www.haskell.org/happy/) que permite generar analizadores sint谩cticos en **Haskell**. 

---

>  **Actividad.**   
> Revisa el cap铆tulo [Using Happy](https://www.haskell.org/happy/doc/html/sec-using.html) de la documentaci贸n de Happy.

---

A continuaci贸n se muestra el archivo de entrada para **Happy**. Requiere la especificaci贸n del analizador l茅xico, los 谩rboles de sintaxis abstracta y genera como salida una funci贸n `parse` que se encarga de generar nuestros ASA.

```haskell
{
module Grammars where

import Data.Char
}

%name parse
%tokentype { Token }
%error { parseError }

%token 
      int             { TokenNum $$ }
      '+'             { TokenSuma }
      '-'             { TokenResta }
      '*'             { TokenMult }
      '/'             { TokenDiv }
      '('             { TokenPA }
      ')'             { TokenPC }

%%

ASA : int                  { Num $1 }
    | '(' '+' ASA ASA ')'  { Suma $3 $4}
    | '(' '-' ASA ASA ')'  { Resta $3 $4}
    | '(' '*' ASA ASA ')'  { Mult $3 $4}
    | '(' '/' ASA ASA ')'  { Div $3 $4} 

{

parseError :: [Token] -> a
parseError _ = error "Parse error"


data ASA = Num Int
          | Suma ASA ASA
          | Resta ASA ASA
          | Mult ASA ASA
          | Div ASA ASA
          deriving(Show)

data Token = TokenNum Int
           | TokenSuma
           | TokenResta
           | TokenMult
           | TokenDiv
           | TokenPA
           | TokenPC
           deriving(Show)

lexer :: String -> [Token]
lexer [] = []
lexer (' ' : xs) = lexer xs
lexer ('(' : xs) = TokenPA:(lexer xs)
lexer (')' : xs) = TokenPC:(lexer xs)
lexer ('+' : xs) = TokenSuma:(lexer xs)
lexer ('-' : xs) = TokenResta:(lexer xs)
lexer ('*' : xs) = TokenMult:(lexer xs)
lexer ('/' : xs) = TokenDiv:(lexer xs)
lexer (x:xs)
    | isDigit x = lexNum (x:xs)

lexNum :: String -> [Token]
lexNum cs = TokenNum (read num) : lexer rest
      where (num,rest) = span isDigit cs

main = getContents >>= print . parse . lexer

}
```

```bash
> parse $ lexer "1729"
Num 1729
> parse $ lexer "(+ 18 35)"
Suma (Num 18) (Num 35)
> parse $ lexer "(+ (- 4 0) (* 5 5))"
Suma (Resta (Num 4) (Num 0)) (Mult (Num 5) (Num 5))
```

## An谩lisis sem谩ntico

Toma en cuenta el ASA y comprueba si, adem谩s de las restricciones sint谩ctica, se cumplen otras restricciones impuestas por el lenguaje y que no pueden ser comprobadas mediante una gram谩tica libre de contexto. El resultado puede resultar en un nuevo 谩rbol o en el resultado final, como es el caso de nuestro lenguaje.

Algunos ejemplos de estas restricciones son la necesidad de declarar variables antes de usarlas, las reglas de tipos o la coincidencia entre los par谩metros de las funciones en las definiciones y las llamadas. En el caso de este lenguaje, no es necesario verificar ninguna restricci贸n adicional.

Procedemos entonces a evaluar las expresiones usando las reglas definidas en la especificaci贸n de la sem谩ntica natural. El mapeo se da mediante la funci贸n `interp`:

```haskell
interp :: ASA -> Int
interp (Num n) = n
interp (Suma i d) = interp i + interp d
interp (Resta i d) = interp i - interp d
interp (Mult i d) = interp i * interp d
interp (Div i d) = div (interp i) (interp d)
```

```bash
> interp $ parse $ lexer "1729"
1729
> interp $ parse $ lexer "(+ 18 35)"
53
> interp $ parse $ lexer "(+ (- 4 0) (* 5 5))"
29
```

## Integraci贸n

Consiste en integrar todos los componentes anteriores en un 煤nico programa. Recordando que nuestro programa est谩 siendo traducido por un int茅rprete, colocaremos todo en un programa [REPL](https://es.wikipedia.org/wiki/REPL), cuyo c贸digo se muestra a continuaci贸n:

```haskell
module REPL where

import Grammars
import Interp

-- Funci贸n encargada de llevar la ejecuci贸n del programa mediante los siguientes pasos:
-- 1. Impresi贸n del propt.
-- 2. Lectura de una cadena.
-- 3. Si la cadana es igual a ":q", se cierra el int茅rprete.
-- 4. En caso contrario, realiza la generaci贸n de c贸digo ejecutable aplicando los an谩lisis en
--    orden siguiente: l茅xico, sint谩ctico, sem谩ntico.
-- 5. Vuelve a ejecutar el ciclo.
repl = 
    do
        putStr "> "
        str <- getLine
        if str == "(exit)" then 
            putStrLn "Bye." 
        else 
            do
                putStrLn $ show (interp (parse (lexer str)))
                repl

-- Funci贸n principal. Da la bienvenida al usuario y ejecuta el REPL.
run =
    do
        putStrLn "Mini-Lisp v1.0. Bienvenidx." 
        repl
```

 [**Descarga aqu铆 el c贸digo de MiniLisp**](codigo)

Para correr el int茅rprete terminado ejecuta:

```bash
> happy Grammars.y 
> ghci REPL.hs 
GHCi, version 8.6.5: http://www.haskell.org/ghc/  :? for help
[1 of 3] Compiling Grammars         ( Grammars.hs, interpreted )
[2 of 3] Compiling Interp           ( Interp.hs, interpreted )
[3 of 3] Compiling REPL             ( REPL.hs, interpreted )
Ok, three modules loaded.
*REPL> run
Mini-Lisp v1.0. Bienvenidx.
> 1729
1729
> (+ 18 35)
53
> (+ (- 4 0) (* 5 5))
29
> (exit)
Bye.
*REPL> 
```

[`Anterior`](../README.md) | [`Siguiente`](../laboratorio02/README.md)
